{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReSys_3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFgYpbhh0tkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f168fc3-0085-41f5-ed50-53f642aa9839"
      },
      "source": [
        "!rm -rf ratings* books* to_read* test*\n",
        "\n",
        "!curl -o ratings.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-ratings.csv\" \n",
        "!curl -o books.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-books.csv\"\n",
        "!curl -o to_read.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-to_read.csv\"\n",
        "!curl -o test.csv \"http://www.dcs.gla.ac.uk/~craigm/recsysH/coursework/final-test.csv\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7631k  100 7631k    0     0  3367k      0  0:00:02  0:00:02 --:--:-- 3369k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2366k  100 2366k    0     0  1777k      0  0:00:01  0:00:01 --:--:-- 1779k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7581k  100 7581k    0     0  4709k      0  0:00:01  0:00:01 --:--:-- 4706k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1895k  100 1895k    0     0  1038k      0  0:00:01  0:00:01 --:--:-- 1037k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VpVnNrZ1EiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754f7989-90ca-4498-dd01-9f5ee2488b6f"
      },
      "source": [
        "#Standard setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "!pip install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight\n",
        "from spotlight.interactions import Interactions\n",
        "SEED=20\n",
        "BPRMF=None"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spotlight\n",
            "  Cloning https://github.com/cmacdonald/spotlight.git (to revision master) to /tmp/pip-install-qonfzs21/spotlight_2298eb45cd964dfeb9de5007e8cd5528\n",
            "  Running command git clone -q https://github.com/cmacdonald/spotlight.git /tmp/pip-install-qonfzs21/spotlight_2298eb45cd964dfeb9de5007e8cd5528\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spotlight) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->spotlight) (3.7.4.3)\n",
            "Building wheels for collected packages: spotlight\n",
            "  Building wheel for spotlight (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spotlight: filename=spotlight-0.1.6-py3-none-any.whl size=34106 sha256=03e55975a13956ccc7d14ab47ac7e75700973a1d29a6afd68219f854a5045277\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kjoslf4a/wheels/1c/2a/31/d187173520bc800643df4e3d1f97dee21d2133ba41085704ed\n",
            "Successfully built spotlight\n",
            "Installing collected packages: spotlight\n",
            "Successfully installed spotlight-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKAb25iw1MYw"
      },
      "source": [
        "#load in the csv files\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "books_df = pd.read_csv(\"books.csv\")\n",
        "to_read_df = pd.read_csv(\"to_read.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6rqfn53OhDC"
      },
      "source": [
        "#cut down the number of items and users\n",
        "counts=ratings_df[ratings_df[\"book_id\"] < 2000].groupby([\"book_id\"]).count().reset_index()\n",
        "valid_books=counts[counts[\"user_id\"] >= 10][[\"book_id\"]]\n",
        "\n",
        "books_df = books_df.merge(valid_books, on=\"book_id\")\n",
        "ratings_df = ratings_df[ratings_df[\"user_id\"] < 2000].merge(valid_books, on=\"book_id\")\n",
        "to_read_df = to_read_df[to_read_df[\"user_id\"] < 2000].merge(valid_books, on=\"book_id\")\n",
        "test = test[test[\"user_id\"] < 2000].merge(valid_books, on=\"book_id\")\n",
        "\n",
        "\n",
        "#stringify the id columns\n",
        "def str_col(df):\n",
        "  if \"user_id\" in df.columns:\n",
        "    df[\"user_id\"] = \"u\" + df.user_id.astype(str)\n",
        "  if \"book_id\" in df.columns:\n",
        "    df[\"book_id\"] = \"b\" + df.book_id.astype(str)\n",
        "\n",
        "str_col(books_df)\n",
        "str_col(ratings_df)\n",
        "str_col(to_read_df)\n",
        "str_col(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ClgJOdTTt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4a5271-b357-40c2-a2cc-f4ad9652a5ba"
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "iid_map = defaultdict(count().__next__)\n",
        "\n",
        "\n",
        "rating_iids = np.array([iid_map[iid] for iid in ratings_df[\"book_id\"].values], dtype = np.int32)\n",
        "test_iids = np.array([iid_map[iid] for iid in test[\"book_id\"].values], dtype = np.int32)\n",
        "toread_iids = np.array([iid_map[iid] for iid in to_read_df[\"book_id\"].values], dtype = np.int32)\n",
        "\n",
        "\n",
        "uid_map = defaultdict(count().__next__)\n",
        "test_uids = np.array([uid_map[uid] for uid in test[\"user_id\"].values], dtype = np.int32)\n",
        "rating_uids = np.array([uid_map[uid] for uid in ratings_df[\"user_id\"].values], dtype = np.int32)\n",
        "toread_uids = np.array([uid_map[iid] for iid in to_read_df[\"user_id\"].values], dtype = np.int32)\n",
        "\n",
        "\n",
        "uid_rev_map = {v: k for k, v in uid_map.items()}\n",
        "iid_rev_map = {v: k for k, v in iid_map.items()}\n",
        "\n",
        "\n",
        "rating_dataset = Interactions(user_ids=rating_uids,\n",
        "                               item_ids=rating_iids,\n",
        "                               ratings=ratings_df[\"rating\"].values,\n",
        "                               num_users=len(uid_rev_map),\n",
        "                               num_items=len(iid_rev_map))\n",
        "\n",
        "toread_dataset = Interactions(user_ids=toread_uids,\n",
        "                               item_ids=toread_iids,\n",
        "                               num_users=len(uid_rev_map),\n",
        "                               num_items=len(iid_rev_map))\n",
        "\n",
        "test_dataset = Interactions(user_ids=test_uids,\n",
        "                               item_ids=test_iids,\n",
        "                               num_users=len(uid_rev_map),\n",
        "                               num_items=len(iid_rev_map))\n",
        "\n",
        "print(rating_dataset)\n",
        "print(toread_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "#here we define the validation set\n",
        "toread_dataset_train, validation = random_train_test_split(toread_dataset, random_state=np.random.RandomState(SEED))\n",
        "\n",
        "num_items = test_dataset.num_items\n",
        "num_users = test_dataset.num_users"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (1999 users x 1826 items x 124762 interactions)>\n",
            "<Interactions dataset (1999 users x 1826 items x 135615 interactions)>\n",
            "<Interactions dataset (1999 users x 1826 items x 33917 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kDxZgICBFp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7dea124-f665-4198-c613-da7397658e21"
      },
      "source": [
        "def getAuthorTitle(iid):\n",
        "  bookid = iid_rev_map[iid]\n",
        "  row = books_df[books_df.book_id == bookid]\n",
        "  return row.iloc[0][\"authors\"] + \" / \" + row.iloc[0][\"title\"]\n",
        "\n",
        "print(\"iid 0: \" + getAuthorTitle(0) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iid 0: Carlos Ruiz Zaf√≥n, Lucia Graves / The Shadow of the Wind (The Cemetery of Forgotten Books,  #1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eaxy_hakbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70196297-f86c-4d4c-9343-929ef5a46a50"
      },
      "source": [
        "from spotlight.evaluation import mrr_score, precision_recall_score\n",
        "\n",
        "class dummymodel:\n",
        "  \n",
        "  def __init__(self, numitems):\n",
        "    self.predictions=np.zeros(numitems)\n",
        "  \n",
        "  #uid is the user we are requesting recommendations for;\n",
        "  #returns an array of scores, one for each item\n",
        "  def predict(self, uid):\n",
        "    #this model returns all zeros, regardless of userid\n",
        "    return( self.predictions )\n",
        "\n",
        "#lets evaluate how the effeciveness of dummymodel\n",
        "\n",
        "print(mrr_score(dummymodel(num_items), test_dataset, train=rating_dataset, k=100).mean())\n",
        "#as expected, a recommendation model that gives 0 scores for all items obtains a MRR score of 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQTJOmS5dB3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd61863-1881-4f4b-f512-8b1a3d8394b4"
      },
      "source": [
        "#note that mrr_score() displays a progress bar if you set verbose=True\n",
        "print(mrr_score(dummymodel(num_items), test_dataset, train=rating_dataset, k=100, verbose=True).mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999it [00:00, 2811.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCWXwVC5Mtyj"
      },
      "source": [
        "#  Combination of Recommendation Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyvGgW_3ZjLV"
      },
      "source": [
        "## Explicit & Implicit Matrix Factorisation Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDADjtepRvpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ea69dd-84a8-4de3-a41e-b3f591591d28"
      },
      "source": [
        "# Add your solution here\n",
        "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
        "import time  \n",
        "\n",
        "emodel = ExplicitFactorizationModel(n_iter=10,\n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
        ")\n",
        "emodel.fit(rating_dataset,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 3.8710271667261593\n",
            "Epoch 1: loss 0.7940810446123607\n",
            "Epoch 2: loss 0.6382512643200452\n",
            "Epoch 3: loss 0.5217335281557725\n",
            "Epoch 4: loss 0.44844855655167926\n",
            "Epoch 5: loss 0.40543351120880394\n",
            "Epoch 6: loss 0.3823863151254224\n",
            "Epoch 7: loss 0.36336620252762664\n",
            "Epoch 8: loss 0.35137936695799477\n",
            "Epoch 9: loss 0.3396692546237199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-0ZqUWA43iV",
        "outputId": "95010c53-28ad-46b6-c26e-c4c1012e2853"
      },
      "source": [
        "from spotlight.evaluation import mrr_score\n",
        "mrr_score(emodel,test_dataset,train=rating_dataset,k=100,verbose=True).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999it [00:02, 957.71it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05898399982013507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI1UFygX30PA",
        "outputId": "68cca134-9182-4cbe-9e72-3a7cc3f146b6"
      },
      "source": [
        "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
        "import time  \n",
        "\n",
        "imodel = ImplicitFactorizationModel(n_iter=10, \n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
        ")\n",
        "imodel.fit(toread_dataset_train,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.7677980539090229\n",
            "Epoch 1: loss 0.53877861825925\n",
            "Epoch 2: loss 0.47017199658560305\n",
            "Epoch 3: loss 0.428322009882837\n",
            "Epoch 4: loss 0.39839018825090156\n",
            "Epoch 5: loss 0.368275504770144\n",
            "Epoch 6: loss 0.3473479778699155\n",
            "Epoch 7: loss 0.32980164804689166\n",
            "Epoch 8: loss 0.31870100696413023\n",
            "Epoch 9: loss 0.3048194432103971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2OcXCqr5TIK",
        "outputId": "3c3709cc-46f5-4a04-abce-68b50147042d"
      },
      "source": [
        "mrr_score(imodel,test_dataset,train=toread_dataset,k=100,verbose=True).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999it [00:02, 966.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3344826076413641"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx3SRiGO4Jtq",
        "outputId": "5c43f09d-f2bb-4972-a02a-e08c15611326"
      },
      "source": [
        "BPRMF=ImplicitFactorizationModel(n_iter=10, \n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED), # ensure results are repeatable\n",
        "                                  loss='bpr'\n",
        ")\n",
        "BPRMF.fit(toread_dataset_train,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.33895447579616644\n",
            "Epoch 1: loss 0.19644999289709442\n",
            "Epoch 2: loss 0.15870640168563938\n",
            "Epoch 3: loss 0.14147728193059284\n",
            "Epoch 4: loss 0.132827276100387\n",
            "Epoch 5: loss 0.12213623321632731\n",
            "Epoch 6: loss 0.11668406535853755\n",
            "Epoch 7: loss 0.11047121562626001\n",
            "Epoch 8: loss 0.10888675406996934\n",
            "Epoch 9: loss 0.10400472129782978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1dHCS1h5dAS",
        "outputId": "bf43b8b2-0696-4bc9-ab81-e99e5b933d58"
      },
      "source": [
        "mrr_score(BPRMF,test_dataset,train=toread_dataset,k=100,verbose=True).mean() #mrr_score the higher the better"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999it [00:02, 947.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41698419515356516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZHCOmfEDOGo"
      },
      "source": [
        "##  Hybrid Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j6JzIOHkYw9"
      },
      "source": [
        "def test_Hybrid_a(combsumObj):\n",
        "  for i, u in enumerate([5, 20]):\n",
        "    print(\"Hybrid a test case %d\" % i)\n",
        "    print(np.count_nonzero(combsumObj.predict(u) > 1))\n",
        "\n",
        "def test_Hybrid_b(pipeObj):\n",
        "  for i, iid in enumerate([3, 0]):\n",
        "    print(\"Hybrid b test case %d\" % i)\n",
        "    print(pipeObj.predict(0)[iid])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_o7a1ppFZ7R"
      },
      "source": [
        "# Add your solutions here and evaluate them\n",
        "\n",
        "class linearModel:\n",
        "  def _init_(self, model1, model2):\n",
        "      self.model1 = model1\n",
        "      self.model2 = model2\n",
        " \n",
        "  def predict(self, uid):\n",
        "      normalisation_Score_1 = minmax_scale(self.model1.predict(uid), feature_range=(0,1), axis=0)\n",
        "      normalisation_Score_2 = minmax_scale(self.model2.predict(uid), feature_range=(0,1), axis=0)\n",
        "      return (normalisation_Score_1 + normalisation_Score_2)  #why returns 0 regardless of uiid?? #check later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtOGMLc8HoI"
      },
      "source": [
        "class pipeModel:\n",
        "  def _init_(self, model1, model2):\n",
        "      self.model1 = model1\n",
        "      self.model2 = model2\n",
        " \n",
        "  def predict(self, uid):\n",
        "    model_1_prediction = self.model_1.prediction(uid)\n",
        "    model_2_prediction = self.model_2.prediction(uid)\n",
        "    \n",
        "    top_100_imf = np.argsort(model_1_prediction)[-100:][::-1]#top 100 items\n",
        "    not_in_imf = np.argsort(model_1_prediction)[::-1][100:] #nearest\n",
        " \n",
        "    final_prediction = model_1_prediction\n",
        " \n",
        "    final_prediction[top_100_imf] = model_2_predict[top_100_imf] #reranking\n",
        "    final_prediction[not_in_imf] = 0    #assinging zero for remaining predictions\n",
        " \n",
        "    return final_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROCBxlfKKkGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "a77d44c1-8ada-4e67-d0c3-25a35356fc7a"
      },
      "source": [
        "#Now test your hybrid approaches for the quiz\n",
        "\n",
        "test_Hybrid_a(linearModel)\n",
        "test_Hybrid_b(pipeModel)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hybrid a test case 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-9725c0a3c7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Now test your hybrid approaches for the quiz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_Hybrid_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinearModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_Hybrid_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-ae0253e84c18>\u001b[0m in \u001b[0;36mtest_Hybrid_a\u001b[0;34m(combsumObj)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hybrid a test case %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombsumObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_Hybrid_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'uid'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf0K6GECM0LQ"
      },
      "source": [
        "#  Analysing Recommendation Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIyc_p_dIm1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac4fa8c-a959-491e-e356-4f6db6a08846"
      },
      "source": [
        "from typing import Sequence, Tuple\n",
        "\n",
        "def get_top_K(model, uid : int, k : int) -> Tuple[ Sequence[int], Sequence[float],  np.ndarray ] :\n",
        "  #returns iids, their (normalised) scores in descending order, and item emebddings for the top k predictions of the given uid.\n",
        "\n",
        "  from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "  from scipy.stats import rankdata\n",
        "  # get scores from model\n",
        "  scores = model.predict(uid)\n",
        "\n",
        "  # map scores into rank 0..1 over the entire item space\n",
        "  scores = minmax_scale(scores)\n",
        "\n",
        "  #compute their ranks  \n",
        "  ranks = rankdata(-scores)\n",
        "  \n",
        "  # get and filter iids, scores and embeddings\n",
        "  rtr_scores = scores[ranks <= k]\n",
        "  rtr_iids = np.argwhere(ranks <= k).flatten()\n",
        "  if hasattr(model, '_net'):\n",
        "    embs = model._net.item_embeddings.weight[rtr_iids]\n",
        "  else:\n",
        "    # not a model that has any embeddings\n",
        "    embs = np.zeros([k,1])\n",
        "  \n",
        "  # identify correct ordering using numpy.argsort()\n",
        "  ordering = (-1*rtr_scores).argsort()\n",
        "  \n",
        "  #return iids, scores and their embeddings in descending order of score\n",
        "  return rtr_iids[ordering], rtr_scores[ordering], embs[ordering]\n",
        "\n",
        "if BPRMF is not None:\n",
        "  iids, scores, embs = get_top_K(BPRMF, 0, 10)\n",
        "  print(\"Returned iids: %s\" % str(iids))\n",
        "  print(\"Returned scores: %s\" % str(scores))\n",
        "  print(\"Returned embeddings: %s\" % str(embs))\n",
        "else:\n",
        "  print(\"You need to define BPRMF in Task 1\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Returned iids: [ 23 108  21  33   9  81  52 254  16   3]\n",
            "Returned scores: [1.         0.9895131  0.9848315  0.92250896 0.9070817  0.90654314\n",
            " 0.9005319  0.89310133 0.88378096 0.8836929 ]\n",
            "Returned embeddings: tensor([[-0.0453,  1.3716, -0.8307, -1.2616,  1.6700,  1.0161,  1.1168,  2.3530,\n",
            "         -1.2027,  0.8522, -1.0941, -0.6865, -0.5725, -2.0335, -1.2591,  0.6154,\n",
            "         -0.1374, -1.6868, -1.8615, -0.7514,  1.9909, -0.3909,  1.9239,  1.3293,\n",
            "         -1.2834, -0.4520,  1.1338,  0.3467,  2.5169, -2.1587,  1.2310,  1.1670],\n",
            "        [ 0.1239,  1.1004,  0.0531, -1.1045,  1.9932,  1.5049,  1.0011,  1.9734,\n",
            "         -1.6322, -0.8913, -0.6372,  0.7721, -1.1422, -2.2424, -1.1936, -0.5770,\n",
            "          0.0762, -1.0283, -1.2807, -2.0889,  2.8154, -0.9600, -0.1419,  0.8408,\n",
            "         -1.6067, -1.2905,  1.9169,  1.3988,  1.8646, -2.2028,  0.5365,  0.2022],\n",
            "        [ 0.3845,  0.8188, -0.1892, -1.1793,  2.1731,  0.6669,  1.1271,  1.4538,\n",
            "         -1.2173, -0.5447, -1.6713,  0.5249, -0.6132, -3.1082, -0.6489,  0.4312,\n",
            "          0.9176, -1.0346, -1.7232, -1.3347,  2.5504,  0.2789,  1.9649,  0.7684,\n",
            "         -1.0310, -1.3983,  0.8985, -0.0562,  2.1894, -0.8905,  1.0992,  0.6691],\n",
            "        [-0.4410,  0.4801, -0.2538, -0.5986,  1.2272,  0.6531,  1.4534,  1.3803,\n",
            "         -1.3796,  0.8305, -1.1837, -0.3366, -0.3528, -1.9982, -1.2018,  0.8934,\n",
            "         -0.5632, -0.6443, -0.7337, -0.4922,  2.9899,  0.2760,  1.4479,  1.0105,\n",
            "         -0.7107, -1.7105, -0.9456, -0.2314,  2.2862, -1.0982,  0.6176,  1.9784],\n",
            "        [-0.5686,  1.3279,  0.0929, -1.1565,  0.5140, -0.1223,  0.8788,  2.0444,\n",
            "          0.2803,  0.6417, -0.3809,  0.2828, -0.3895, -2.7013, -1.4182,  0.2742,\n",
            "         -1.0461, -1.5824, -2.0993, -1.3979,  1.3412, -0.4346,  1.5427,  1.2284,\n",
            "         -2.0168, -1.3083,  0.2939,  2.2792,  1.2569, -0.8994,  1.0784, -0.0203],\n",
            "        [ 0.1340,  0.2584, -0.5791, -0.5029,  2.7529,  0.0107,  0.8058,  2.3262,\n",
            "         -1.9017, -0.4165, -1.4422, -0.7689, -0.7657, -1.3836,  0.7729, -0.0596,\n",
            "          0.1377, -0.9144, -1.0304, -2.4873,  2.4421, -0.2146,  1.3113,  2.0114,\n",
            "         -0.5655, -1.5423,  1.9430,  2.1211,  1.2265, -0.4562,  0.4370,  1.1741],\n",
            "        [ 0.5933,  1.3073,  0.5726, -0.0917,  1.6623,  1.3124,  0.8131,  1.4753,\n",
            "         -1.6077,  1.4744, -0.6149, -0.1318,  0.2843, -2.1551, -1.0225,  1.1611,\n",
            "         -0.7732, -1.3496, -0.7587, -1.4566,  1.8771,  0.2448,  0.9532,  0.2902,\n",
            "         -1.4033, -1.9129,  1.0374, -0.1574,  2.0627, -1.1652,  0.8938,  0.7756],\n",
            "        [ 0.6018,  1.0445, -0.5415,  0.5355,  1.4569,  0.5330,  0.2956,  1.5574,\n",
            "         -0.2669, -1.4242,  1.5775,  1.0870, -0.6438, -1.5680, -1.4657,  1.3033,\n",
            "         -0.6602, -0.7102, -1.1306, -1.5143,  1.2747,  0.5494, -0.2278,  1.8629,\n",
            "         -1.8720, -0.3860,  1.0929,  1.4837,  1.2602, -1.6316, -0.4450,  0.6793],\n",
            "        [-0.4931, -0.2156, -1.0300, -1.1251,  2.3141,  0.1844,  0.0278,  1.1525,\n",
            "         -0.3218, -0.2236, -0.9952,  0.4091, -0.8533, -2.1377, -2.0955,  0.4107,\n",
            "         -0.5804, -1.6455, -1.4729, -2.6273,  1.5917, -0.3359,  2.3430,  0.6596,\n",
            "         -1.4888, -1.8436,  1.2947,  2.4997,  1.9382, -0.2631,  0.8980,  0.6717],\n",
            "        [-0.6251,  1.0291, -0.9705, -0.5551,  1.3933,  1.4241,  0.6316,  0.8137,\n",
            "         -0.1443, -0.4631,  0.1315, -0.3589, -0.3534, -1.7652, -0.1728,  0.4081,\n",
            "         -2.4594, -2.0278, -0.9450, -1.9469,  0.8574, -0.0176,  0.7410,  0.8268,\n",
            "         -0.9872, -1.0237,  1.6763,  1.2756,  1.2099, -0.8075,  1.2227,  1.8007]],\n",
            "       grad_fn=<IndexBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVYiQRYaEh61"
      },
      "source": [
        "## Evaluation of Non-personalised Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xop8aPfyFucw"
      },
      "source": [
        "class StaticModel:\n",
        "  \n",
        "  def __init__(self, staticscores):\n",
        "    self.numitems = len(staticscores)\n",
        "    #print(self.numitems)\n",
        "    assert isinstance(staticscores, np.ndarray), \"Expected a numpy array\"\n",
        "    assert staticscores.dtype == np.float32 or staticscores.dtype == np.float64, \"Expected a numpy array of floats\"\n",
        "    self.staticscores = staticscores\n",
        "  \n",
        "  def predict(self, uid):\n",
        "    #this model returns the same scores for each user    \n",
        "    return self.staticscores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R1q-Zm7FVM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "2520f5b7-0162-43fa-eeff-48b7e2e764d4"
      },
      "source": [
        "# Add your solution here\n",
        "average_rating=ratings_df['rating'].mean\n",
        "average_rating\n",
        "mod=StaticModel(average_rating.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-01529ab94a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maverage_rating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mratings_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maverage_rating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStaticModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_rating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZqRSixpGvfn"
      },
      "source": [
        "## Qualiatively Examining Recommendations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg1eFa5GYv5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa930a6-c271-4245-e56c-33b44e0a462d"
      },
      "source": [
        "# Add your solution here\n",
        "def book_recommendation(uid : int):\n",
        "  #books that the user previously shelved\n",
        "  book=toread_dataset.item_ids[toread_dataset.user_ids == uid]\n",
        "  for iid in book:\n",
        "    previously_shelved=getAuthorTitle(iid)\n",
        "    print (\"A:\", previously_shelved)  \n",
        "  \n",
        "  #books that the user read in the future\n",
        "  book=test_dataset.item_ids[test_dataset.user_ids == uid]\n",
        "  for iid in book:\n",
        "    future_books=getAuthorTitle(iid)\n",
        "    print (\"B:\", future_books)\n",
        "\n",
        "  #top 10 books recommended by BPRMF\n",
        "  recommendation_bprmf=get_top_K(BPRMF,uid,10)\n",
        "  recommendation_bprmf=recommendation_bprmf[0]\n",
        "  for iid in recommendation_bprmf:\n",
        "    top_10=getAuthorTitle(iid)\n",
        "    print(\"C:\", top_10)\n",
        "  \n",
        "book_recommendation(1805)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: Stieg Larsson, Reg Keeland / The Girl Who Kicked the Hornet's Nest (Millennium, #3)\n",
            "A: Suzanne Collins / Mockingjay (The Hunger Games, #3)\n",
            "A: Dennis Lehane / Shutter Island\n",
            "A: Suzanne Collins / Catching Fire (The Hunger Games, #2)\n",
            "A: Paula Hawkins / The Girl on the Train\n",
            "A: Robert Ludlum / The Bourne Supremacy (Jason Bourne, #2)\n",
            "A: John Grisham / The Client\n",
            "A: Thomas Harris / The Silence of the Lambs  (Hannibal Lecter, #2)\n",
            "A: Daphne du Maurier, Sally Beauman / Rebecca\n",
            "A: Robert Ludlum / The Bourne Identity (Jason Bourne, #1)\n",
            "A: Robert Galbraith, J.K. Rowling / The Cuckoo's Calling (Cormoran Strike, #1)\n",
            "A: Stephen King / Misery\n",
            "A: Michael Crichton / Jurassic Park (Jurassic Park, #1)\n",
            "A: Robert Ludlum / The Bourne Ultimatum (Jason Bourne, #3)\n",
            "A: Stephen King, Bernie Wrightson / The Stand\n",
            "A: Michael Crichton / The Andromeda Strain\n",
            "A: Thomas Harris / Red Dragon (Hannibal Lecter, #1)\n",
            "A: Lee Child / Die Trying (Jack Reacher, #2)\n",
            "A: Lee Child / Worth Dying For (Jack Reacher, #15)\n",
            "A: Lee Child / Tripwire  (Jack Reacher, #3)\n",
            "A: Michael Crichton / Congo\n",
            "A: Lee Child, Dick Hill / Without Fail (Jack Reacher, #6)\n",
            "A: Michael Crichton / The Lost World (Jurassic Park, #2)\n",
            "A: Janet Evanovich / One for the Money (Stephanie Plum, #1)\n",
            "A: Tom Clancy / Patriot Games (Jack Ryan Universe, #2)\n",
            "A: Lee Child / Running Blind (Jack Reacher, #4)\n",
            "A: Ken Follett / Eye of the Needle\n",
            "A: Michael Crichton / State of Fear\n",
            "A: Scott Turow / Presumed Innocent\n",
            "A: Harlan Coben / Tell No One\n",
            "B: John Grisham / The Pelican Brief\n",
            "B: Stieg Larsson, Reg Keeland / The Girl Who Played with Fire (Millennium, #2)\n",
            "B: Gillian Flynn / Gone Girl\n",
            "B: Tom Clancy / The Hunt for Red October (Jack Ryan Universe, #4)\n",
            "B: Chuck Palahniuk / Fight Club\n",
            "B: Umberto Eco, William Weaver, Se√°n Barrett / The Name of the Rose\n",
            "B: John Grisham / The Runaway Jury\n",
            "B: Thomas Harris / Hannibal (Hannibal Lecter, #3)\n",
            "B: Lee Child / The Affair (Jack Reacher, #16)\n",
            "B: John Grisham / The Firm (Penguin Readers, Level 5)\n",
            "B: Lee Child / Killing Floor (Jack Reacher, #1)\n",
            "B: John Grisham / A Time to Kill\n",
            "B: Stephen King / The Shining (The Shining #1)\n",
            "B: Michael Crichton / Timeline\n",
            "B: Michael Crichton / Prey\n",
            "B: Jeffery Deaver / The Bone Collector (Lincoln Rhyme, #1)\n",
            "C: Suzanne Collins / The Hunger Games (The Hunger Games, #1)\n",
            "C: Dan Brown / The Da Vinci Code (Robert Langdon, #2)\n",
            "C: Dan Brown / The Lost Symbol (Robert Langdon, #3)\n",
            "C: Michael Crichton / Disclosure\n",
            "C: George R.R. Martin / A Clash of Kings  (A Song of Ice and Fire, #2)\n",
            "C: Dan Brown / Angels & Demons  (Robert Langdon, #1)\n",
            "C: John Grisham / The Broker\n",
            "C: Khaled Hosseini / The Kite Runner\n",
            "C: George R.R. Martin / A Game of Thrones (A Song of Ice and Fire, #1)\n",
            "C: Suzanne Collins / Mockingjay (The Hunger Games, #3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_zHeCkNBeC"
      },
      "source": [
        "#  Diversity of Recommendations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvBep-ROHWSX"
      },
      "source": [
        "## . Measuring Intra-List Diversity\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n2vBwcnYuM4"
      },
      "source": [
        "# Add your solution here\n",
        "def measure_ild(top_books : Sequence[int], K : int=5) -> float:\n",
        "  ILD = 0.0\n",
        "  return ILD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qwrP1jUpARF"
      },
      "source": [
        "## Task 6. Implement MMR Diversification \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VkEMfRvIhKV"
      },
      "source": [
        "from typing import Sequence\n",
        "def mmr(iids : Sequence[int], scores : Sequence[float], embs : np.ndarray, alpha : float) -> Sequence[int]:\n",
        "\n",
        "  assert len(iids) == len(scores)\n",
        "  assert len(iids) == embs.shape[0]\n",
        "  assert len(embs.size()) == 2\n",
        "\n",
        "\n",
        "  rtr_iids=iids\n",
        "  \n",
        "  #input your solution here returns a re-ordering of iids, such that the first ranked item is first in the list\n",
        "\n",
        "  return rtr_iids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34QWxFVTfrLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c2771d-2461-4bd2-ff16-d9f0c885d0ad"
      },
      "source": [
        "def run_MMR_testcases(mmrfn):\n",
        "  example_embeddings1 = torch.tensor([[1.0,1.0],[1.0,1.0],[0,1.0],[0.1, 1.0]])\n",
        "  example_embeddings2 = torch.tensor([[1.0,1.0],[1.0,1.0],[0.02,1.0],[0.01,1.0]])\n",
        "  print(\"Testcase 0 : %s\" % mmrfn([1,2,3,4], [0.5, 0.5, 0.5, 0.5],  example_embeddings1, 0.5)[0] )\n",
        "  print(\"Testcase 1 : %s\" % mmrfn([1,2,3,4], [0.5, 0.5, 0.5, 0.5],  example_embeddings1, 0.5)[1] )\n",
        "  print(\"Testcase 2 : %s\" % mmrfn([1,2,3,4], [4, 3, 2, 1],  example_embeddings1, 1)[1] )\n",
        "  print(\"Testcase 3 : %s\" % mmrfn([1,2,3,4], [0.99, 0.98, 0.97, 0.001],  example_embeddings2, 0.001)[1] )\n",
        "  print(\"Testcase 4 : %s\" % mmrfn([1,2,3,4], [0.99, 0.98, 0.97, 0.001],  example_embeddings2, 0.5)[1] )\n",
        "\n",
        "run_MMR_testcases(mmr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testcase 0 : 1\n",
            "Testcase 1 : 2\n",
            "Testcase 2 : 2\n",
            "Testcase 3 : 2\n",
            "Testcase 4 : 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}