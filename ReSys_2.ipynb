{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReSys_2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys992pU79yhD"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import List, Tuple, Sequence\n",
        "SEED=20"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg093kVRAvHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93c9186-f715-4098-ebe7-e3f9447b1071"
      },
      "source": [
        "!curl -o ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "# backup location\n",
        "#!curl -o ml-latest-small.zip http://www.dcs.gla.ac.uk/~craigm/recsysHM/ml-latest-small.zip\n",
        "!unzip -o ml-latest-small.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  955k  100  955k    0     0   499k      0  0:00:01  0:00:01 --:--:--  499k\n",
            "Archive:  ml-latest-small.zip\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yss68U_EA0w2"
      },
      "source": [
        "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
        "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
        "\n",
        "# we're going to treat userId as strings, and similarly as movies. This will prevent confusion later on.\n",
        "ratings_df['userId'] =  \"u\" + ratings_df['userId'].astype(str)\n",
        "ratings_df['movieId'] = \"m\" + ratings_df['movieId'].astype(str)\n",
        "movies_df['movieId'] = \"m\" +  movies_df['movieId'].astype(str)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5QQBZ3QS2Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "27dbff3f-5b9d-414f-bbb4-be91f94267f3"
      },
      "source": [
        "ratings_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1</td>\n",
              "      <td>m1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u1</td>\n",
              "      <td>m3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u1</td>\n",
              "      <td>m6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u1</td>\n",
              "      <td>m47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u1</td>\n",
              "      <td>m50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  userId movieId  rating  timestamp\n",
              "0     u1      m1     4.0  964982703\n",
              "1     u1      m3     4.0  964981247\n",
              "2     u1      m6     4.0  964982224\n",
              "3     u1     m47     5.0  964983815\n",
              "4     u1     m50     5.0  964982931"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMfsveWjS4xP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3c70b268-0a68-44e8-ef05-896ed892813a"
      },
      "source": [
        "movies_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>m4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movieId  ...                                       genres\n",
              "0      m1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1      m2  ...                   Adventure|Children|Fantasy\n",
              "2      m3  ...                               Comedy|Romance\n",
              "3      m4  ...                         Comedy|Drama|Romance\n",
              "4      m5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rAIXwDoBCda"
      },
      "source": [
        "#  User-based CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKsmW549BNlq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "da97cfb1-a44d-4ff9-c5ce-9742aaeac504"
      },
      "source": [
        "r_df_matrix = ratings_df.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "r_df_matrix"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>movieId</th>\n",
              "      <th>m1</th>\n",
              "      <th>m10</th>\n",
              "      <th>m100</th>\n",
              "      <th>m100044</th>\n",
              "      <th>m100068</th>\n",
              "      <th>m100083</th>\n",
              "      <th>m100106</th>\n",
              "      <th>m100159</th>\n",
              "      <th>m100163</th>\n",
              "      <th>m100194</th>\n",
              "      <th>m100226</th>\n",
              "      <th>m100277</th>\n",
              "      <th>m1003</th>\n",
              "      <th>m100302</th>\n",
              "      <th>m100304</th>\n",
              "      <th>m100306</th>\n",
              "      <th>m100326</th>\n",
              "      <th>m100383</th>\n",
              "      <th>m100390</th>\n",
              "      <th>m100397</th>\n",
              "      <th>m1004</th>\n",
              "      <th>m100487</th>\n",
              "      <th>m100498</th>\n",
              "      <th>m1005</th>\n",
              "      <th>m100507</th>\n",
              "      <th>m100527</th>\n",
              "      <th>m100553</th>\n",
              "      <th>m100556</th>\n",
              "      <th>m100579</th>\n",
              "      <th>m1006</th>\n",
              "      <th>m100611</th>\n",
              "      <th>m1007</th>\n",
              "      <th>m100714</th>\n",
              "      <th>m100737</th>\n",
              "      <th>m1008</th>\n",
              "      <th>m100810</th>\n",
              "      <th>m100843</th>\n",
              "      <th>m100882</th>\n",
              "      <th>m1009</th>\n",
              "      <th>m100906</th>\n",
              "      <th>...</th>\n",
              "      <th>m98836</th>\n",
              "      <th>m98908</th>\n",
              "      <th>m98961</th>\n",
              "      <th>m99</th>\n",
              "      <th>m990</th>\n",
              "      <th>m99005</th>\n",
              "      <th>m99007</th>\n",
              "      <th>m99030</th>\n",
              "      <th>m99087</th>\n",
              "      <th>m991</th>\n",
              "      <th>m99106</th>\n",
              "      <th>m99112</th>\n",
              "      <th>m99114</th>\n",
              "      <th>m99117</th>\n",
              "      <th>m99122</th>\n",
              "      <th>m99130</th>\n",
              "      <th>m99145</th>\n",
              "      <th>m99149</th>\n",
              "      <th>m99191</th>\n",
              "      <th>m993</th>\n",
              "      <th>m994</th>\n",
              "      <th>m99415</th>\n",
              "      <th>m99437</th>\n",
              "      <th>m99532</th>\n",
              "      <th>m99574</th>\n",
              "      <th>m996</th>\n",
              "      <th>m99636</th>\n",
              "      <th>m99638</th>\n",
              "      <th>m99721</th>\n",
              "      <th>m99728</th>\n",
              "      <th>m99750</th>\n",
              "      <th>m99764</th>\n",
              "      <th>m998</th>\n",
              "      <th>m99813</th>\n",
              "      <th>m99846</th>\n",
              "      <th>m99853</th>\n",
              "      <th>m999</th>\n",
              "      <th>m99910</th>\n",
              "      <th>m99917</th>\n",
              "      <th>m99992</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>u1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u100</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u101</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u102</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u95</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u96</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u97</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u98</th>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u99</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>610 rows  9724 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "movieId   m1  m10  m100  m100044  m100068  ...  m99853  m999  m99910  m99917  m99992\n",
              "userId                                     ...                                      \n",
              "u1       4.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u10      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u100     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u101     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u102     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "...      ...  ...   ...      ...      ...  ...     ...   ...     ...     ...     ...\n",
              "u95      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u96      5.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u97      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u98      4.5  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u99      0.0  4.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "\n",
              "[610 rows x 9724 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRIXYwQgBRt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd1a54b-0c33-465d-dcca-964013f8742c"
      },
      "source": [
        "r_df_matrix.index"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['u1', 'u10', 'u100', 'u101', 'u102', 'u103', 'u104', 'u105', 'u106',\n",
              "       'u107',\n",
              "       ...\n",
              "       'u90', 'u91', 'u92', 'u93', 'u94', 'u95', 'u96', 'u97', 'u98', 'u99'],\n",
              "      dtype='object', name='userId', length=610)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77XOSOdqBXmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79be411b-8b9c-4b88-f000-87d076c28536"
      },
      "source": [
        "r_df_matrix.loc['u1']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "movieId\n",
              "m1         4.0\n",
              "m10        0.0\n",
              "m100       0.0\n",
              "m100044    0.0\n",
              "m100068    0.0\n",
              "          ... \n",
              "m99853     0.0\n",
              "m999       0.0\n",
              "m99910     0.0\n",
              "m99917     0.0\n",
              "m99992     0.0\n",
              "Name: u1, Length: 9724, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NXXbCQsBbJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb4ef6d-1726-4b13-aef9-98e246705387"
      },
      "source": [
        "def cos_sim(a, b):\n",
        "  from numpy.linalg import norm\n",
        "  from numpy import dot\n",
        "  return dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "print('Cosine similarity between userId=1 and itself is:')\n",
        "print(cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u1'].values))\n",
        "\n",
        "print('Cosine similarity between userId=1 and userId=607 is:')\n",
        "print(cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u607'].values))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between userId=1 and itself is:\n",
            "1.0\n",
            "Cosine similarity between userId=1 and userId=607 is:\n",
            "0.2693892401115333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj1wpnS7BbMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4bf4d0-86f4-42ba-c3ca-35f74dcec338"
      },
      "source": [
        "from scipy.stats import rankdata\n",
        "\n",
        "def get_most_similar_users(userId : str, k : int = 10) -> Tuple[Sequence[str], Sequence[float]]:\n",
        "  # Add your solution here\n",
        "  sim_user=[]\n",
        "  user_cos=[]\n",
        "  for i in r_df_matrix.index:\n",
        "    similarity=cos_sim(r_df_matrix.loc[userId].values,r_df_matrix.loc[i].values)#u(i) -> cos_sim[u(userId)]\n",
        "    sim_user.append(i)\n",
        "    user_cos.append(similarity)\n",
        "  #store the values in the df\n",
        "  df=pd.DataFrame(list(zip(sim_user,user_cos)),columns=['userId','cosine_similarity'])\n",
        "  df=df.sort_values(by=['cosine_similarity'],ascending=False) #sorting\n",
        "  \n",
        "  #from index = 1 since index 0 is the user itself\n",
        "  topk_userids = df.userId[1:k+1].tolist() # a list/numpy array of k userIds of top-k users\n",
        "  topk_cosines = df.cosine_similarity[1:k+1].tolist() # a list/numpy array of k cosine similarity values\n",
        "  return (topk_userids, topk_cosines)\n",
        "\n",
        "print(get_most_similar_users(userId='u3', k=1))\n",
        "\n",
        "# Add your solution here (cosine similarity > 0)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['u313'], [0.07818732282993371])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ZepSCnBwc7"
      },
      "source": [
        "##  Predict ratings via user-based CF.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eX33RkTBbS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477275e8-1816-4703-fc6d-c95b47974c65"
      },
      "source": [
        "def predict_rating(userId : str, movieId : str) -> float:\n",
        "  # add your solution here\n",
        "  #get the similar users, cosine_sim from the get_most_similar_users\n",
        "  similar_user,cosine_sim = get_most_similar_users(userId,10)#k=10\n",
        "  user_similarity_sum=0 \n",
        "  predicted=0  #ypred\n",
        "  for i in range(0,len(similar_user)): #for every user and its similar users\n",
        "    if r_df_matrix.loc[similar_user[i],movieId]!=0: #if the similar user rated that item\n",
        "      user_similarity_sum += cosine_sim[i] #denominator \n",
        "      predicted +=cosine_sim[i] * r_df_matrix.loc[similar_user[i],movieId] #if 2(user_sim)*3(rating)\n",
        "  predicted = predicted/user_similarity_sum #total_predicted/total_user_similarities\n",
        "\n",
        "  #predicted = \"?\" # predicted rating value\n",
        "  return predicted\n",
        "\n",
        "print(\"Predicted rating:\", predict_rating(userId='u1', movieId='m1'))\n",
        "\n",
        "print(\"Actual rating:\", r_df_matrix.loc['u1']['m1'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating: 3.898822026597358\n",
            "Actual rating: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqfUghVsCA7G"
      },
      "source": [
        "##  Predict ratings via user-based CF with Mean-center normalisation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q5Efb4zB5_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae833e2-5573-4dbd-83f6-d9a1dd0c5780"
      },
      "source": [
        "def mean_rating(userId : str) -> float: #mean rating of the user \n",
        "  # add your solution here\n",
        "  movies_rated_by_user=len(np.array(r_df_matrix.loc[userId]).nonzero()[0]) #return non zero elements in the array\n",
        "  mean_rating = np.sum(r_df_matrix.loc[userId]/movies_rated_by_user) # mean-centering value\n",
        "  return mean_rating\n",
        "\n",
        "print(\"Mean rating of user u5:\", mean_rating('u5') )\n",
        "\n",
        "def predict_rating_MC(userId : str, movieId : str) -> float:\n",
        "  # add your solution here \n",
        "  #same predict_rating function \n",
        "  #with users_mean_rating bias considered\n",
        "\n",
        "  similar_user,cosine_sim = get_most_similar_users(userId,10)#k=10\n",
        "  user_similarity_sum=0 \n",
        "  predicted=0  #ypred\n",
        "  users_mean_rating=mean_rating(userId) #users mean raiting = user bias\n",
        "  for i in range(0,len(similar_user)): #for every user and its similar users\n",
        "    if r_df_matrix.loc[similar_user[i],movieId]!=0: #if the similar user rated that item\n",
        "      user_similarity_sum += cosine_sim[i] #denominator \n",
        "      #user mean -> user bias\n",
        "      users_mean = mean_rating(similar_user[i])\n",
        "      predicted +=cosine_sim[i] * ( r_df_matrix.loc[similar_user[i],movieId] - users_mean) #if 2(user_sim)*3(rating)\n",
        "  predicted = users_mean_rating+ predicted/user_similarity_sum #total_predicted/total_user_similarities\n",
        " # predicted = \"?\" # predicted rating value with mean-centering\n",
        "  return predicted\n",
        "\n",
        "print(\"Predicted rating:\", predict_rating_MC('u1', 'm1'))\n",
        "print(\"Actual rating:\", r_df_matrix.loc['u1']['m1'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean rating of user u5: 3.6363636363636367\n",
            "Predicted rating: 4.769198526598025\n",
            "Actual rating: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN_OpdQYHmTb"
      },
      "source": [
        "#Explicit Matrix Factorisation using Spotlight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDObURPI-Shz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb45843-8321-4c57-e63e-948430af830c"
      },
      "source": [
        "!pip install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spotlight\n",
            "  Cloning https://github.com/cmacdonald/spotlight.git (to revision master) to /tmp/pip-install-v6lm2xzl/spotlight_6e617cdd32fb4040986a0014f4b11836\n",
            "  Running command git clone -q https://github.com/cmacdonald/spotlight.git /tmp/pip-install-v6lm2xzl/spotlight_6e617cdd32fb4040986a0014f4b11836\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spotlight) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->spotlight) (3.7.4.3)\n",
            "Building wheels for collected packages: spotlight\n",
            "  Building wheel for spotlight (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spotlight: filename=spotlight-0.1.6-py3-none-any.whl size=34106 sha256=f07ca8b0c45d4703a42fbbe96e33c194e35bcff3d9d997c7ac87b44b043198cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vzff7le_/wheels/1c/2a/31/d187173520bc800643df4e3d1f97dee21d2133ba41085704ed\n",
            "Successfully built spotlight\n",
            "Installing collected packages: spotlight\n",
            "Successfully installed spotlight-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF89PzxNHrHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be60c330-0489-42c2-dfe4-d88ad8911221"
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "#create userId -> uid mapping dictionary. the next assigned value is the current size.\n",
        "uid_map = defaultdict(count().__next__)\n",
        "#ditto for movieId -> iid\n",
        "iid_map = defaultdict(count().__next__)\n",
        "\n",
        "#uids is an array of integers corresponding to the userId for every row in ratings_df\n",
        "#uid_map does the assignment of new uid values, or reusing the uid value assigned for\n",
        "#each userId\n",
        "uids = np.array([uid_map[uid] for uid in ratings_df[\"userId\"].values ], dtype=np.int32)\n",
        "#similar for iids\n",
        "iids = np.array([iid_map[iid] for iid in ratings_df[\"movieId\"].values ], dtype=np.int32)\n",
        "\n",
        "#freeze uid_map and iid_map so no more mappings are created\n",
        "uid_map.default_factory = None\n",
        "iid_map.default_factory = None\n",
        "\n",
        "#reverse them, so we can go from iid (int) to itemId (str)\n",
        "uid_rev_map = {v: k for k, v in uid_map.items()}\n",
        "iid_rev_map = {v: k for k, v in iid_map.items()}\n",
        "num_items = len(iid_map)\n",
        "num_users = len(uid_map)\n",
        "\n",
        "print(\"%d users %d item\" % (num_users, num_items))\n",
        "\n",
        "ratings = ratings_df[\"rating\"].values.astype(np.float32)\n",
        "timestamps = ratings_df[\"timestamp\"].values.astype(np.int32)\n",
        "\n",
        "print(\"userId %s got uid %d\" % (\"u556\", uid_map[\"u556\"]))\n",
        "print(\"movieId %s got iid %d\" % (\"m54001\", iid_map[\"m54001\"]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610 users 9724 item\n",
            "userId u556 got uid 555\n",
            "movieId m54001 got iid 2518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDwZYy2xY3-D"
      },
      "source": [
        "## On towards MF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg2tNWwPIBfu"
      },
      "source": [
        "from spotlight.interactions import Interactions\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "dataset = Interactions(user_ids=uids,\n",
        "                                  item_ids=iids,\n",
        "                                  ratings=ratings,\n",
        "                                  timestamps=timestamps)\n",
        "\n",
        "#lets initialise the seed, so that its repeatable and reproducible \n",
        "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(SEED))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcjOWJ-qIEge",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c37dfd8-4632-466e-ce9f-ebd9c8dc64fb"
      },
      "source": [
        "print(train)\n",
        "print(test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Interactions dataset (610 users x 9724 items x 80668 interactions)>\n",
            "<Interactions dataset (610 users x 9724 items x 20168 interactions)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBnevuHnT57k"
      },
      "source": [
        "Here, you can see that following the collaborative filtering task model (see Lecture 6), all users, and all items, are present in both training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74iQtBOoUZJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242562d7-94ab-4915-ad88-50972d9e9add"
      },
      "source": [
        "print(train.item_ids.shape)\n",
        "print(train.user_ids.shape)\n",
        "print(train.ratings.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80668,)\n",
            "(80668,)\n",
            "(80668,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz46dNMkUrCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98f727e-c4cb-44e9-aa6c-7e7bdf789014"
      },
      "source": [
        "print(\"uid %d gave iid %d a rating of %d\" % (train.user_ids[0], train.item_ids[0],train.ratings[0]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uid 56 gave iid 1491 a rating of 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47QmgWtYvM4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fd45f3-ef48-4e99-bdf8-8b8de4e47dd4"
      },
      "source": [
        "# map userId to the internal uid value\n",
        "userId = \"u556\"\n",
        "uid = uid_map.get(userId)\n",
        "\n",
        "# see which ratings are for this user. Use this to filter the item and ratings arrays. \n",
        "# here we are filtering a numpy array based on an array of True/False values. Its just\n",
        "# like filtering a Pandas data frame.\n",
        "print(train.item_ids[train.user_ids == uid])\n",
        "print(train.ratings[train.user_ids == uid])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6082 6087  457 1925 7951 1132  764 5989  753 1342 1893 3076 3258 1182\n",
            " 1938 1894 4796  926  770 8659 2059  917 1077  912  779  322 1307 3087\n",
            " 2518  774]\n",
            "[4.  3.5 5.  5.  4.  4.  4.  4.  4.5 4.  4.  4.5 4.  4.  4.5 3.5 4.  4.\n",
            " 4.  4.  4.  3.5 5.  2.5 4.  5.  4.  4.  4.  4. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UduCmnlbKt-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07061c6-c93b-4bf4-edcf-bf6ad2257958"
      },
      "source": [
        "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
        "import time  \n",
        "\n",
        "emodel = ExplicitFactorizationModel(n_iter=10,\n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
        ")\n",
        "current = time.time()\n",
        "\n",
        "emodel.fit(train, verbose=True)\n",
        "\n",
        "end = time.time()\n",
        "diff = end - current\n",
        "print(\"Training took %d seconds \"% (diff))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss 4.3081090674747395\n",
            "Epoch 1: loss 0.8099101063194154\n",
            "Epoch 2: loss 0.5096786571077153\n",
            "Epoch 3: loss 0.3636633798102789\n",
            "Epoch 4: loss 0.2919712789073775\n",
            "Epoch 5: loss 0.25697739233699024\n",
            "Epoch 6: loss 0.23643478482395788\n",
            "Epoch 7: loss 0.22271784451566165\n",
            "Epoch 8: loss 0.2139979781983774\n",
            "Epoch 9: loss 0.20728877597028697\n",
            "Training took 13 seconds \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjyVPjoGLoy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeab53dd-218e-4c42-d9ee-f8a443c2f519"
      },
      "source": [
        "userId = \"u556\"\n",
        "\n",
        "# convert the string to the internal integer\n",
        "uid = uid_map.get(userId)\n",
        "print(\"One test item_id for userId %s (uid %d) is \" % (userId, uid))\n",
        "\n",
        "# pick one rating that the user made\n",
        "testItemId = test.item_ids[test.user_ids == uid][0] \n",
        "print(\"Test movieId is %s iid %d \" % (iid_rev_map.get(testItemId), testItemId ) )\n",
        "\n",
        "\n",
        "#here 0 is a dummy item, which Spotlight needs for some reason...\n",
        "#we discard its prediction using [1]\n",
        "predicted = emodel.predict( np.array([uid]), item_ids=np.array([0, testItemId]) )[1]\n",
        "\n",
        "#what was the actual score of the user for that movie?\n",
        "#we can get the appropriate row from the ratings dataframe, then extract that value\n",
        "actual = ratings_df[(ratings_df.movieId==iid_rev_map.get(testItemId)) & (ratings_df.userId==userId)][\"rating\"].values[0]\n",
        "\n",
        "\n",
        "def getMovieTitle(iid):\n",
        "  return movies_df[movies_df['movieId'] == iid_rev_map.get(iid)][\"title\"].values[0]\n",
        "\n",
        "print(\"Predicted rating for '%s' was %f, actual rating %0.1f, error was %f\" % (getMovieTitle(testItemId), predicted, actual, abs(predicted-actual) )) \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One test item_id for userId u556 (uid 555) is \n",
            "Test movieId is m74530 iid 8141 \n",
            "Predicted rating for 'Percy Jackson & the Olympians: The Lightning Thief (2010)' was 2.574092, actual rating 3.5, error was 0.925908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz28wrmIsDa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e8b233-baa0-487f-b51c-fcb4e6e96f71"
      },
      "source": [
        "allpreds = emodel.predict( np.array([uid]) )\n",
        "\n",
        "print(allpreds)\n",
        "print(allpreds.size)\n",
        "\n",
        "#we can recover the original rating for our test item \n",
        "print(allpreds[testItemId])\n",
        "\n",
        "# lets just check we got the correct prediction\n",
        "print(allpreds[testItemId] - actual < 0.1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.9689248  4.3499784  4.5101566  ... 0.87423515 2.7873065  0.9850692 ]\n",
            "9724\n",
            "2.5740924\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25P7AtBPgXS"
      },
      "source": [
        "## Latent Factors aka Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf2Em9KSa74G",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa163243-3807-4482-e39d-473b6e2d4a34"
      },
      "source": [
        "#the embedding of an item is a PyTorch tensor of size 32\n",
        "#a PyTorch tensor can be thought of having similar semantics as an numpy array.\n",
        "print(emodel._net.item_embeddings.weight[0].shape)\n",
        "emodel._net.item_embeddings.weight[0]\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1223, -0.3951, -0.3488,  0.0474,  0.7867, -0.0242,  0.2448,  0.7672,\n",
              "        -0.1924, -0.0686, -0.1228,  0.6061, -0.1798, -0.3621,  0.7326,  0.2025,\n",
              "        -0.1660, -0.3077, -0.3590, -0.3852,  0.2369, -0.6257,  0.7370,  0.8468,\n",
              "         0.0755, -0.4360, -0.1154, -0.2451, -0.0357, -0.0060,  0.1001,  0.2164],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g14v62m4YRyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c459b0bf-5530-435d-b553-5a89658bde7e"
      },
      "source": [
        "# uid=555 for u556\n",
        "# testItemId is our item of interest\n",
        "\n",
        "dotprod = (emodel._net.user_embeddings.weight[uid] * emodel._net.item_embeddings.weight[testItemId]).sum(0)\n",
        "user_bias = emodel._net.user_biases(torch.tensor([uid]))\n",
        "item_bias = emodel._net.item_biases(torch.tensor([testItemId], dtype=torch.long))\n",
        "\n",
        "print(getMovieTitle(testItemId))\n",
        "\n",
        "dotprod + user_bias + item_bias"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percy Jackson & the Olympians: The Lightning Thief (2010)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5741]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VE2tpcJb8e7"
      },
      "source": [
        "##  Examining Latent Factors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7fDGUx6fBR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e763ba16-1bda-4b1d-e141-bc489a1520fe"
      },
      "source": [
        "import torch.nn as nn\n",
        "nn.functional.cosine_similarity(\n",
        "     torch.tensor([1.0,0]),\n",
        "     torch.tensor([0,1.0],), dim=0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KBjz4Yu8PAF",
        "outputId": "850d893d-2e86-40c4-c6f5-1e80ad68eba6"
      },
      "source": [
        "targetIId=iid_map[\"m81834\"]\n",
        "a=emodel._net.item_embeddings.weight[targetIId]\n",
        "a #to get the embedding weights of the target movie"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7272, -0.3795,  0.1719, -0.8317,  0.7841, -0.0126,  0.0426,  0.7044,\n",
              "        -0.4959,  0.4894, -0.1102,  0.4305, -0.6199, -0.0366,  0.1803,  0.2544,\n",
              "        -0.2255,  0.3797, -0.2439, -0.1055,  0.4677, -0.0541,  0.0852,  0.9091,\n",
              "        -0.3590, -0.9817, -0.1562,  0.3706, -0.2103, -0.0146,  0.5229, -0.1545],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rg_DuBnoMEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d362012-50a7-4a25-9e7d-20e41188d8e6"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def mostsimilar(targetIId : int, model):\n",
        "  highest=0\n",
        "  highestCos=0\n",
        "  \n",
        "  #you may assume that model._num_items provides thetotal number of items\n",
        "  latent_embedding= emodel._net.item_embeddings.weight[targetIId] #latent embeddings of the targetIID\n",
        "  for i in range(emodel._num_items):\n",
        "    if i!=targetIId:\n",
        "      latent_i = emodel._net.item_embeddings.weight[i] #embeddings of i\n",
        "      cosine_sim= nn.functional.cosine_similarity(latent_embedding,latent_i,dim=0) #cos_sim(a,b)\n",
        "      if cosine_sim>highestCos:\n",
        "        highestCos=cosine_sim\n",
        "        highest = i #update till we get the most similar item\n",
        "\n",
        "  ##SOLUTION FROM HERE\n",
        "\n",
        "  #####################\n",
        "\n",
        "  print(train.num_items)\n",
        "  print(\"targetMovieId = %s '%s' (iid %d)\" % (iid_rev_map.get(targetIId), getMovieTitle(targetIId), targetIId))\n",
        "  print(\"mostSimilar = %s (iid %d) with cosine of %f \" % ( iid_rev_map.get(highest), highest, highestCos))\n",
        "  \n",
        "  \n",
        "mostsimilar(iid_map[\"m81834\"], emodel)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9724\n",
            "targetMovieId = m81834 'Harry Potter and the Deathly Hallows: Part 1 (2010)' (iid 1933)\n",
            "mostSimilar = m69844 (iid 917) with cosine of 0.793590 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgUvFR0AK8XI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e25a82-e8b8-4a02-f1a0-b01e1e4b2d3c"
      },
      "source": [
        "mostsimilar(iid_map[\"m88125\"], emodel)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9724\n",
            "targetMovieId = m88125 'Harry Potter and the Deathly Hallows: Part 2 (2011)' (iid 1938)\n",
            "mostSimilar = m69844 (iid 917) with cosine of 0.765978 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENhT5FXX3qH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf143b2c-f88c-4a0f-db5d-6fb340a13d3f"
      },
      "source": [
        "mostsimilar(iid_map[\"m44\"], emodel)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9724\n",
            "targetMovieId = m44 'Mortal Kombat (1995)' (iid 971)\n",
            "mostSimilar = m107338 (iid 2836) with cosine of 0.641703 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxHfMZgbcdRu"
      },
      "source": [
        "## Evaluating performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB8UJykycm3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82707fab-13a8-4af0-8001-1c71b1f9261e"
      },
      "source": [
        "from spotlight.evaluation import rmse_score\n",
        "\n",
        "train_rmse = rmse_score(emodel, train)\n",
        "test_rmse = rmse_score(emodel, test)\n",
        "\n",
        "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE 0.421, test RMSE 1.078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcRrTWx9lkoo"
      },
      "source": [
        "##  Tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AUFN-ZqB_Jt"
      },
      "source": [
        "#solution here\n",
        "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
        "from spotlight.evaluation import rmse_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "def model(embedding_dim):\n",
        "  emodel = ExplicitFactorizationModel(n_iter=10,\n",
        "                                    embedding_dim=embedding_dim, #different factors\n",
        "                                    use_cuda=False, #rest default\n",
        "                                    random_state=np.random.RandomState(SEED) \n",
        "                                    )\n",
        "  return emodel\n",
        "  \n",
        "e_dim = [8,16,32,64]\n",
        "times=[]\n",
        "rmse_train_values = []\n",
        "rmse_test_values = []\n",
        "for embedding_dim in e_dim:\n",
        "  eemodel = model(embedding_dim) #calling the function\n",
        "  a=time.time()\n",
        "  eemodel.fit(train, verbose=False) #fit function\n",
        "  #get the rmse values\n",
        "  b=time.time()\n",
        "  total_time=b-a\n",
        "  train_rmse_values = rmse_score(eemodel, train)\n",
        "  test_rmse_values = rmse_score(eemodel, test)\n",
        "  #append the vlaues to the list\n",
        "  rmse_train_values.append(train_rmse_values)\n",
        "  rmse_test_values.append(test_rmse_values)\n",
        "  times.append(total_time)\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMPFM67rWRNg",
        "outputId": "1695449c-59aa-49fe-c009-02edf071e461"
      },
      "source": [
        "times #time increases"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.059175968170166, 9.417245388031006, 13.239948511123657, 21.474222421646118]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYD9ldG0E7Xs",
        "outputId": "12f78ee2-07b6-4916-da17-d28460f5e5dd"
      },
      "source": [
        "rmse_test_values"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.010825, 1.047683, 1.0784731, 1.0378313]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9iOen1tE9ox",
        "outputId": "bb3ea63e-d6e6-4593-fce4-b38474782775"
      },
      "source": [
        "rmse_train_values"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.57729393, 0.48349097, 0.42138827, 0.46829987]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "aoCjVuauEo1G",
        "outputId": "caa43917-0805-4219-ec5a-abd970a8e3bc"
      },
      "source": [
        "\n",
        "plt.plot(e_dim,rmse_train_values,label='Training RMSE values',linewidth=1.5,marker='+')\n",
        "plt.plot(e_dim,rmse_test_values,label='Testing RMSE values',linewidth=1.5,marker='+')\n",
        "plt.xlabel('Latent Factors')\n",
        "plt.ylabel('RMSE values')\n",
        "plt.xticks(e_dim)\n",
        "plt.legend()\n",
        "plt.savefig('Task 5 - Tuning.png')\n",
        "plt.show\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYTtH0_pl6sj"
      },
      "source": [
        "## Evaluating Other Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Xd1X4TX2Tq"
      },
      "source": [
        "class StaticModel:\n",
        "  \n",
        "  def __init__(self, staticscores):\n",
        "    self.numitems = len(staticscores)\n",
        "    self.staticscores = staticscores\n",
        "  \n",
        "  #uids are the user(s) we are requesting recommendations for;\n",
        "  #returns an array of scores, one for each item\n",
        "  #the array is duplicated for each user requested\n",
        "  def predict(self, uids, iids=None):\n",
        "    #this model returns all zeros, regardless of userid\n",
        "    \n",
        "    #we respond to one or more uids\n",
        "    uids = [uids] if isinstance(uids, int) else uids\n",
        "\n",
        "    #if iids is specificed, we filter predicts for those userids\n",
        "    iids = np.arange(self.numitems) if iids is None else iids\n",
        "    return [self.staticscores[iids] for u in uids]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3FVJWJzYhoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71df10c9-2ace-45a1-cb3f-beebd04d15cd"
      },
      "source": [
        "mydummymodel = StaticModel(np.zeros(num_items))\n",
        "\n",
        "print(\"Asking for 2 users, one item: \" + str(mydummymodel.predict([0,1],0)))\n",
        "print(\"Asking for one item: \" + str(mydummymodel.predict(0,0)))\n",
        "print(\"Asking for two items: \" + str(mydummymodel.predict(0,[0,1])))\n",
        "print(\"RMSE of our dummy model: %f\" % rmse_score(mydummymodel, test))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking for 2 users, one item: [0.0, 0.0]\n",
            "Asking for one item: [0.0]\n",
            "Asking for two items: [array([0., 0.])]\n",
            "RMSE of our dummy model: 3.642758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSnTtOzAoA2l"
      },
      "source": [
        "## Popularity-based Recommenders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ff_L2dMAGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ff29c3-79df-40d1-bbbf-dfcf74964aa7"
      },
      "source": [
        "#solution here\n",
        "#task a - Normalise ratings for each item\n",
        "\n",
        "items_df=ratings_df[[\"movieId\",\"rating\"]].groupby([\"movieId\"])\n",
        "total_items=items_df.count() #denominator\n",
        "#[(a-min)/(max-min)]*5 -> Normalisation to 5 \n",
        "total_items['rating'] = (total_items['rating'] -  total_items['rating'].min())/(total_items['rating'].max()-total_items['rating'].min())*5\n",
        "total_items['rating'].values"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.26219512, 1.99695122, 0.19817073, ..., 0.0152439 , 0.0304878 ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAE3Pw_7J4uh",
        "outputId": "7df1e211-3284-40db-a367-3b564fc07eb8"
      },
      "source": [
        "mydummymodel = StaticModel(total_items['rating'].values)\n",
        "\n",
        "print(\"Asking for 2 users, one item: \" + str(mydummymodel.predict([0,1],0)))\n",
        "print(\"Asking for one item: \" + str(mydummymodel.predict(0,0)))\n",
        "print(\"Asking for two items: \" + str(mydummymodel.predict(0,[0,1])))\n",
        "print(\"RMSE of our dummy model: %f\" % rmse_score(mydummymodel, test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking for 2 users, one item: [3.2621951219512195, 3.2621951219512195]\n",
            "Asking for one item: [3.2621951219512195]\n",
            "Asking for two items: [array([3.26219512, 1.99695122])]\n",
            "RMSE of our dummy model: 3.514168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJXO0HIZKJGP"
      },
      "source": [
        "#task b- Normalise the 5 star scores\n",
        "five_star_items = items_df.rating.agg(lambda x: x[x==5.0].value_counts() if len(x[x==5.0].value_counts()==0) else 0)\n",
        "\n",
        "five_star_items=np.array(five_star_items.values)\n",
        "#same normalisation like before\n",
        "five_star_items=(five_star_items - five_star_items.min())/(five_star_items.max() - five_star_items.min()) * 5"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCFLQWLGM-sn",
        "outputId": "3ec14ee7-b8c5-4f1f-df4a-a1eed9443d5b"
      },
      "source": [
        "five_star_items"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.53594771, 0.32679739, 0.        , ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkJhy4bkNBnO",
        "outputId": "e12c6ddb-e62d-4c33-a13a-adb96ccde366"
      },
      "source": [
        "#dummy model with five_star_items\n",
        "mydummymodel = StaticModel(five_star_items)\n",
        "\n",
        "print(\"Asking for 2 users, one item: \" + str(mydummymodel.predict([0,1],0)))\n",
        "print(\"Asking for one item: \" + str(mydummymodel.predict(0,0)))\n",
        "print(\"Asking for two items: \" + str(mydummymodel.predict(0,[0,1])))\n",
        "print(\"RMSE of our dummy model: %f\" % rmse_score(mydummymodel, test))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking for 2 users, one item: [1.5359477124183007, 1.5359477124183007]\n",
            "Asking for one item: [1.5359477124183007]\n",
            "Asking for two items: [array([1.53594771, 0.32679739])]\n",
            "RMSE of our dummy model: 3.590646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Zed0c_NOhV",
        "outputId": "2ad0e2d3-6d73-4c0e-b876-bce0d3691f3d"
      },
      "source": [
        "#task c- average rating value - no normalisation\n",
        "average_rating= items_df.agg(average_rating=('rating',np.mean))\n",
        "average_rating['average_rating'].values"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.92093023, 3.49621212, 2.78571429, ..., 3.25      , 3.16666667,\n",
              "       3.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx4g0Qk1NnZr",
        "outputId": "66c6fd12-b720-4b34-fdf7-af4e1c60c334"
      },
      "source": [
        "#dummy model for average rating \n",
        "mydummymodel = StaticModel(average_rating['average_rating'].values)\n",
        "\n",
        "print(\"Asking for 2 users, one item: \" + str(mydummymodel.predict([0,1],0)))\n",
        "print(\"Asking for one item: \" + str(mydummymodel.predict(0,0)))\n",
        "print(\"Asking for two items: \" + str(mydummymodel.predict(0,[0,1])))\n",
        "print(\"RMSE of our dummy model: %f\" % rmse_score(mydummymodel, test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking for 2 users, one item: [3.9209302325581397, 3.9209302325581397]\n",
            "Asking for one item: [3.9209302325581397]\n",
            "Asking for two items: [array([3.92093023, 3.49621212])]\n",
            "RMSE of our dummy model: 1.418723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aCiYTWaeobQ"
      },
      "source": [
        "# Implicit Recommendation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-drWmULel_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b740193-c278-4404-b8a9-0baff2208cbd"
      },
      "source": [
        "!rm -rf lastfm-dataset-1K.tar.gz\n",
        "!curl -o \"lastfm-dataset-1K.tar.gz\" \"http://www.dcs.gla.ac.uk/~craigm/recsysH/lastfm-dataset-1K.tar.gz\"\n",
        "#backup location\n",
        "#!curl -o \"lastfm-dataset-1K.tar.gz\" http://macavaney.us/misc/lastfm-dataset-1K.tar.gz\n",
        "!tar -zxvf lastfm-dataset-1K.tar.gz\n",
        "!ls -lh lastfm-dataset-1K/"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  641M  100  641M    0     0  10.4M      0  0:01:01  0:01:01 --:--:-- 11.1M\n",
            "lastfm-dataset-1K/\n",
            "lastfm-dataset-1K/userid-profile.tsv\n",
            "lastfm-dataset-1K/README.txt\n",
            "lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\n",
            "total 2.4G\n",
            "-rw-r--r-- 1 1002 1002 2.2K Mar 23  2010 README.txt\n",
            "-rw-r--r-- 1 1002 1002  37K Dec 30  2009 userid-profile.tsv\n",
            "-rw-r--r-- 1 1002 1002 2.4G Mar  4  2010 userid-timestamp-artid-artname-traid-traname.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxILh_-h773"
      },
      "source": [
        "listens_df = pd.read_csv(\"lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\",  names=['user', 'timestamp', 'artistid', 'artist', 'trackid', 'trackname'], header=None, sep='\\t')\n",
        "\n",
        "#Some tracks dont seem to have artists or track names, so lets drop them for simplicity.\n",
        "listens_df = listens_df[listens_df.artist.notnull()]\n",
        "listens_df = listens_df[listens_df.trackname.notnull()]\n",
        "\n",
        "#the dataframe is VERY big (19M interactions), so lets just work with a small sample of it (this will mean that effectiveness will be lower, but learning will be MUCH faster).\n",
        "listens_df = listens_df.sample(n=200000, random_state=np.random.RandomState(SEED))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAP3dPt-4KMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "d393a9f0-7501-45d6-a4aa-61739e7a57d8"
      },
      "source": [
        "listens_df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>artistid</th>\n",
              "      <th>artist</th>\n",
              "      <th>trackid</th>\n",
              "      <th>trackname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11087179</th>\n",
              "      <td>user_000593</td>\n",
              "      <td>2007-05-14T18:49:03Z</td>\n",
              "      <td>ad996aef-cc1c-42ac-af5c-619c370f4b8a</td>\n",
              "      <td>Emerson, Lake &amp; Palmer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three Fates (Clotho/Lachesis/Atropos)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911790</th>\n",
              "      <td>user_000093</td>\n",
              "      <td>2008-08-18T22:04:59Z</td>\n",
              "      <td>8c538f11-c141-4588-8ecb-931083524186</td>\n",
              "      <td>Bloc Party</td>\n",
              "      <td>315a301e-e764-4adf-91c6-e90a22320106</td>\n",
              "      <td>Positive Tension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099786</th>\n",
              "      <td>user_000594</td>\n",
              "      <td>2008-04-06T10:57:45Z</td>\n",
              "      <td>65f4f0c5-ef9e-490c-aee3-909e7ae6b2ab</td>\n",
              "      <td>Metallica</td>\n",
              "      <td>683c89fe-2be8-4ed2-8e58-68b2343cb8d5</td>\n",
              "      <td>Through The Never</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12076983</th>\n",
              "      <td>user_000651</td>\n",
              "      <td>2008-05-10T07:14:45Z</td>\n",
              "      <td>3ca09fae-fdee-4771-bab9-244708515a98</td>\n",
              "      <td>Omarion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ice Box [Orangefuzzz Weather Advisory Radio Mix]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680461</th>\n",
              "      <td>user_000137</td>\n",
              "      <td>2009-03-11T23:17:22Z</td>\n",
              "      <td>af84ee9f-534a-4f7f-844b-188ba1c47e87</td>\n",
              "      <td>Los Rodrguez</td>\n",
              "      <td>76b83f07-3763-4c17-8d24-28040d85354a</td>\n",
              "      <td>Dulce Condena</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 user  ...                                         trackname\n",
              "11087179  user_000593  ...             Three Fates (Clotho/Lachesis/Atropos)\n",
              "1911790   user_000093  ...                                  Positive Tension\n",
              "11099786  user_000594  ...                                 Through The Never\n",
              "12076983  user_000651  ...  Ice Box [Orangefuzzz Weather Advisory Radio Mix]\n",
              "2680461   user_000137  ...                                     Dulce Condena\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcRhNWXzg7LT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c89b2c-d202-4197-e1d1-9b7a80cd54ac"
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "#we cant trust the musicbrainz ids to exist, so lets build items ids based on artist & trackname attributes\n",
        "LFMiid_map = defaultdict(count().__next__)\n",
        "LFMiids = np.array([LFMiid_map[artist+\"/\"+trackname] for artist,trackname in listens_df[[\"artist\",\"trackname\"]].values ], dtype=np.int32)\n",
        "\n",
        "LFMuid_map = defaultdict(count().__next__)\n",
        "LFMuids = np.array([LFMuid_map[uid] for uid in listens_df[\"user\"].values ], dtype=np.int32)\n",
        "#freeze uid_map and iid_map so no more mapping are created\n",
        "LFMuid_map.default_factory = None\n",
        "LFMiid_map.default_factory = None\n",
        "\n",
        "LFMuid_rev_map = {v: k for k, v in LFMuid_map.items()}\n",
        "LFMiid_rev_map = {v: k for k, v in LFMiid_map.items()}\n",
        "\n",
        "from spotlight.interactions import Interactions\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "#NB: we will set num_users and num_items here - its a good practice.\n",
        "imp_dataset = Interactions(user_ids=LFMuids, item_ids=LFMiids, num_users=len(LFMuid_map), num_items=len(LFMiid_map))\n",
        "#we could add the timestamps here if we were doing sequence recommendation\n",
        "\n",
        "#what have we got.\n",
        "print(imp_dataset)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Interactions dataset (973 users x 125076 items x 200000 interactions)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dmr7JKqUnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a364b5c-c56c-4554-a5d8-c21f96aa22f3"
      },
      "source": [
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "itrain, itest = random_train_test_split(imp_dataset, random_state=np.random.RandomState(SEED))\n",
        "print(itrain)\n",
        "print(itest)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Interactions dataset (973 users x 125076 items x 160000 interactions)>\n",
            "<Interactions dataset (973 users x 125076 items x 40000 interactions)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3ZwYgkhKvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608a410b-c867-42dc-ef05-08705d301d22"
      },
      "source": [
        "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
        "import time  \n",
        "\n",
        "imodel = ImplicitFactorizationModel(n_iter=5, \n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
        ")\n",
        "current = time.time()\n",
        "\n",
        "imodel.fit(itrain, verbose=True)\n",
        "end = time.time()\n",
        "diff = end - current\n",
        "print(\"Training took %d seconds\" % (diff))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss 0.9663112537384033\n",
            "Epoch 1: loss 0.4953250964164734\n",
            "Epoch 2: loss 0.19036926743984223\n",
            "Epoch 3: loss 0.11518938970565797\n",
            "Epoch 4: loss 0.08347186335921288\n",
            "Training took 156 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR_qbWXEhUDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08775a04-9e30-4c6a-d8e1-4ad75682407e"
      },
      "source": [
        "print(imodel.predict(0))\n",
        "print(len(imodel.predict(0)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ -4.757586   5.261482  -9.297717 ...  -9.027796 -11.657988 -13.502052]\n",
            "125076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyZ3PyAxhdDF"
      },
      "source": [
        "\n",
        "\n",
        "##  Track Analysis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V93_Bxw3MG1F"
      },
      "source": [
        "#your solution here\n",
        "from scipy.stats import rankdata\n",
        "def tracksForUser(user,k): \n",
        "  #k-number of tracks\n",
        "  tracks=np.arange(imodel._num_items)\n",
        "  user_score=imodel.predict(user)\n",
        "  ranking=rankdata(user_score,method='ordinal')#ranking the user_scores\n",
        "  #sort the ranks to the tracks\n",
        "  sorted_tracks= [x for i,x in sorted(zip(ranking,tracks),reverse=True)]\n",
        "  top_k_tracks=sorted_tracks[0:k] #gives top k sorted tracks\n",
        "  \n",
        "  recommended_list=[]\n",
        "  for i in top_k_tracks:\n",
        "    recommended_list.append(LFMiid_rev_map.get(i))\n",
        "\n",
        "  return recommended_list\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmfqPUckb5U8",
        "outputId": "c186f81c-6d75-4ac3-f0e1-80350ae228b9"
      },
      "source": [
        "tracksForUser(4,10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Evanescence/Sweet Sacrifice',\n",
              " 'Mgmt/Kids',\n",
              " 'The Killers/Bones',\n",
              " 'Nelly Furtado/Say It Right',\n",
              " 'Kings Of Leon/Use Somebody',\n",
              " 'Amy Winehouse/Back To Black',\n",
              " 'Red Hot Chili Peppers/The Zephyr Song',\n",
              " 'Radiohead/Fake Plastic Trees',\n",
              " 'Incubus/Drive',\n",
              " 'Him/The Funeral Of Hearts']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWFSAuQ40p2Y"
      },
      "source": [
        "## Artist Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wFfGfcMJcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "88afafa8-5714-4f3d-87a6-436718c6a41c"
      },
      "source": [
        "#your solution here\n",
        "listens_df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>artistid</th>\n",
              "      <th>artist</th>\n",
              "      <th>trackid</th>\n",
              "      <th>trackname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11087179</th>\n",
              "      <td>user_000593</td>\n",
              "      <td>2007-05-14T18:49:03Z</td>\n",
              "      <td>ad996aef-cc1c-42ac-af5c-619c370f4b8a</td>\n",
              "      <td>Emerson, Lake &amp; Palmer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three Fates (Clotho/Lachesis/Atropos)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911790</th>\n",
              "      <td>user_000093</td>\n",
              "      <td>2008-08-18T22:04:59Z</td>\n",
              "      <td>8c538f11-c141-4588-8ecb-931083524186</td>\n",
              "      <td>Bloc Party</td>\n",
              "      <td>315a301e-e764-4adf-91c6-e90a22320106</td>\n",
              "      <td>Positive Tension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099786</th>\n",
              "      <td>user_000594</td>\n",
              "      <td>2008-04-06T10:57:45Z</td>\n",
              "      <td>65f4f0c5-ef9e-490c-aee3-909e7ae6b2ab</td>\n",
              "      <td>Metallica</td>\n",
              "      <td>683c89fe-2be8-4ed2-8e58-68b2343cb8d5</td>\n",
              "      <td>Through The Never</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12076983</th>\n",
              "      <td>user_000651</td>\n",
              "      <td>2008-05-10T07:14:45Z</td>\n",
              "      <td>3ca09fae-fdee-4771-bab9-244708515a98</td>\n",
              "      <td>Omarion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ice Box [Orangefuzzz Weather Advisory Radio Mix]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680461</th>\n",
              "      <td>user_000137</td>\n",
              "      <td>2009-03-11T23:17:22Z</td>\n",
              "      <td>af84ee9f-534a-4f7f-844b-188ba1c47e87</td>\n",
              "      <td>Los Rodrguez</td>\n",
              "      <td>76b83f07-3763-4c17-8d24-28040d85354a</td>\n",
              "      <td>Dulce Condena</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 user  ...                                         trackname\n",
              "11087179  user_000593  ...             Three Fates (Clotho/Lachesis/Atropos)\n",
              "1911790   user_000093  ...                                  Positive Tension\n",
              "11099786  user_000594  ...                                 Through The Never\n",
              "12076983  user_000651  ...  Ice Box [Orangefuzzz Weather Advisory Radio Mix]\n",
              "2680461   user_000137  ...                                     Dulce Condena\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "wPJguVUBdMPG",
        "outputId": "71791c10-9a9d-40f0-af56-d6cdd0cef8d0"
      },
      "source": [
        "#your solution here\n",
        "artist_df = pd.DataFrame(listens_df[['user','artist']].groupby(['user','artist']).artist.agg('count'))\n",
        "artist_df.columns =['Frequency']\n",
        "artist_df.sort_values(by=['Frequency'], ascending = False).loc[LFMuid_rev_map.get(4),:] #u4"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>artist</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Soda Stereo</th>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gustavo Cerati</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Radiohead</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lucybell</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Silvio Rodrguez</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scissor Sisters</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sanalejo</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Saiko</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rihanna</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Porcupine Tree</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows  1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Frequency\n",
              "artist                     \n",
              "Soda Stereo              39\n",
              "Gustavo Cerati           36\n",
              "Radiohead                31\n",
              "Lucybell                 27\n",
              "Silvio Rodrguez         16\n",
              "...                     ...\n",
              "Scissor Sisters           1\n",
              "Sanalejo                  1\n",
              "Saiko                     1\n",
              "Rihanna                   1\n",
              "Porcupine Tree            1\n",
              "\n",
              "[146 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmTNae6Romuk"
      },
      "source": [
        "## Evaluating an implicit recommender\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLV71LSjt-k2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcba86c-bc17-410f-87d1-d6f3acd73688"
      },
      "source": [
        "from spotlight.evaluation import mrr_score\n",
        "\n",
        "#evaluate on this dataset takes approx 1 minute\n",
        "!date\n",
        "print(mrr_score(imodel, itest).mean())\n",
        "!date\n",
        "print(mrr_score(imodel, itest,  train=itrain).mean())\n",
        "!date\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 11 14:15:52 UTC 2021\n",
            "0.03720125940064275\n",
            "Mon Oct 11 14:16:27 UTC 2021\n",
            "0.008104536778740273\n",
            "Mon Oct 11 14:17:03 UTC 2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL2jRiGF2uLb"
      },
      "source": [
        "## Task 9. Listens and Recommendations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6H0l1S6nNcd"
      },
      "source": [
        "#solution goes here.\n",
        "rr_user = mrr_score(imodel, itest)\n",
        "rr_1 = np.where(rr_user == 1)[0][0] #lowest uid wiht RR =1 \n",
        "user_1 = itrain.user_ids[rr_1] #corresponding userId"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8QjXQVGmJQg",
        "outputId": "cd7dfcf2-b326-4bf9-ee92-77c8cb7d4758"
      },
      "source": [
        "user_1 #???"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSUpCcFOnk0Z",
        "outputId": "f18a0907-bdac-49de-e077-18e364eccb53"
      },
      "source": [
        "#no. of listens\n",
        "song_user_1=itrain.item_ids[itrain.user_ids==user_1]\n",
        "song_user_1.size #109 listens???"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzKwpIA2nB7C",
        "outputId": "6ef8a2df-875b-4459-a6e5-e2506d224426"
      },
      "source": [
        "rr_min=np.where(rr_user == rr_user.min())[0][0]\n",
        "user_min=itrain.user_ids[rr_min]\n",
        "user_min #what is this??? #check later"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBp0svEjndAs",
        "outputId": "a826e04f-eff7-4710-99ff-229ba54f27d9"
      },
      "source": [
        "song_user_min=itrain.item_ids[itrain.user_ids==user_min]\n",
        "song_user_min.size #387 listens??"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "387"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDX7dn_oGhA"
      },
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCI34-U48HHI"
      },
      "source": [
        "#solution goes here\n",
        "\n",
        "n_songs=[]\n",
        "userids =[] \n",
        "for user in range(imodel._num_users):\n",
        "  n_songs.append(len(itrain.item_ids[itrain.user_ids==user]))\n",
        "  userids.append(LFMuid_rev_map.get(user))\n",
        "\n",
        "users_df= pd.DataFrame(userids,columns=['user'])\n",
        "users_df['n_songs'] = n_songs"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "fNygAIMHpmVG",
        "outputId": "3052ef34-6b36-45bf-e310-b648ab88bc97"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(np.array(n_songs),log=True)#log=True\n",
        "plt.xlabel(\"Number_of_users\")\n",
        "plt.ylabel(\"Number_of_songs\")\n",
        "plt.savefig('Task 9 - Distribution.png')\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNJw3KGNp66O"
      },
      "source": [
        "#normal user >20 listen\n",
        "n_songs=np.array(n_songs)\n",
        "normal_users=np.where(n_songs>=20)\n",
        "#rest cold start user\n",
        "cold_start_users=np.where(n_songs<20)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dJXv7rhqx3-",
        "outputId": "642b35c8-1977-4136-8a8a-487354642cf9"
      },
      "source": [
        "len(normal_users[0]),len(cold_start_users[0])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(811, 162)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4lMWCJPq63L"
      },
      "source": [
        "#calculating mrr_score\n",
        "mrr_score=mrr_score(imodel,itest)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RlICZKarE8N",
        "outputId": "9172ff46-fb36-434c-db54-9e7dacd35acf"
      },
      "source": [
        "#for normla users\n",
        "normal_mrr=np.take(mrr_score,normal_users[0]).mean()\n",
        "normal_mrr"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04414792633041709"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmQmxcY5rUBd",
        "outputId": "62d1c1bb-e157-46c3-e25a-c10e4870be43"
      },
      "source": [
        "#for cold start\n",
        "cold_mrr=np.take(mrr_score,cold_start_users[0]).mean()\n",
        "cold_mrr #for mrr the higheer the better #normal user is better to recommend than cold start"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0024250440917107582"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR_l43rFc7eo"
      },
      "source": [
        "##  - BPR\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oiCB4PuMQ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fa1794-a298-4a45-cecf-deac0ad39a6c"
      },
      "source": [
        "#solution goes here\n",
        "#implict factorisation model with BPR\n",
        "#default setting with loss='bpr'\n",
        "bpr=ImplicitFactorizationModel(n_iter=5,embedding_dim=32,use_cuda=False,random_state=np.random.RandomState(SEED),loss='bpr')\n",
        "#fit the model with training data\n",
        "a=time.time()\n",
        "bpr.fit(itrain,verbose=True)\n",
        "b=time.time()\n",
        "total_time=b-a\n",
        "total_time #pointwist time = 158 seconds #pointwise loss = 0.083"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss 0.4740972354888916\n",
            "Epoch 1: loss 0.14683696522712708\n",
            "Epoch 2: loss 0.024808155296742917\n",
            "Epoch 3: loss 0.014375447143614292\n",
            "Epoch 4: loss 0.01111387666836381\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156.71679019927979"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "7PbQ1OyohavZ",
        "outputId": "fcf187eb-45d1-4158-f9e3-63d4006fcce1"
      },
      "source": [
        "!date\n",
        "print(mrr_score(bpr, itest).mean())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 11 14:26:08 UTC 2021\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-5060ba17dd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmrr_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-4TCzMVhajf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}